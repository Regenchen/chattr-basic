---
title: "Analyzing contingent interactions in R with chattr"
bibliography: library.bib
csl: apa6.csl
document-params: "10pt, letterpaper"

author-information: > 
    \author{{\large \bf Marisa Casillas (mcasillas@uchicago.edu)} \\ Department of Comparative Human Development, Rosenwald Hall, 3rd floor \\ 1101 East 58th St. \\ Chicago, IL 60637 USA

abstract: >
    Include no author information in the initial submission, to facilitate
    blind review.  The abstract should be one paragraph, indented 1/8 inch on both sides,
    in 9~point font with single spacing. The heading 'Abstract'
    should be 10~point, bold, centered, with one line of space below
    it. This one-paragraph abstract section is required only for standard
    six page proceedings papers. Following the abstract should be a blank
    line, followed by the header 'Keywords' and a list of
    descriptive keywords separated by semicolons, all in 9~point font, as
    shown below.
    
keywords: >
    Add your choice of indexing terms or keywords; kindly use a semi-colon; between each term.
    
output: cogsci2016::cogsci_paper
#final-submission: \cogscifinalcopy
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, 
                      fig.pos = "tb", fig.path='figs/',
                      echo=F, warning=F, cache=F, 
                      message=F, sanitize = T)
```

```{r, libraries}
library(png)
library(grid)
library(ggplot2)
library(xtable)
```


The current paper introduces an R (REFS) package called `chattr` that facilitates the detection and analysis of temporally contingent interactions in pre-annotated data ([https://github.com/marisacasillas/chattr-basic]()).[^1] Current tools for conducting similar analyses from annotated data are either proprietary, thereby limiting access to potential users, or constructed ad-hoc, thereby introducing significant variation in the constructs being measured. The chattr package aims to improve this situation in two ways: (1) it takes inspiration from the fields of conversation analysis, psycholinguistics, and language development to provide flexible but theoretically sound measurements of temporally contingent interaction at scale and (2) its open-source toolkit accepts a handful of generic formats as input, opening up its analytical framework to a wide variety of domains (e.g., child language input, multi-party adult conversation, non-human animal signal exchanges, multi-modal contingencies produced by a single organism, etc.). The remainder of this short report reviews the theoretical basis underlying the development of chattr, describes the core functions offered by the package, and demonstrates its use in three existing datasets.

[^1]: At time of submission, the conversion from R scripts to R package is still underway. That said, all documentation, scripts, and tests are available at the given URL. The fully packaged version will be available at the same URL (minus "-basic") by April 2021.

## Contingent interaction

The joint coordination of action by two or more agents usually involves temporal contingencies of one kind or another. Whether we are making music with others, crossing a busy intersection, or chatting with a friend, the timing of our contributions to the coordinated event is crucial to its success. In many cases, the optimal strategy for coordination involves some form of turn taking. In a typical turn-taking interaction, only one interactant makes their contribution at a time, and decisions about who contributes when can be determined flexibly (as in conversation) or in a pre-defined manner (as in a debate). This sequential structure enables interactants to adapt each contribution such that it relevantly progresses the joint activity and to initiate unplanned subsequences (e.g., repairing a misunderstanding) without breaking from moving toward the the larger goal.

Turn-taking interactions, or temporally contingent interactions that appear much like them, are used for communication across the animal kingdom (REFS). In humans, turn-taking interactions may be the only reliable source of language universals (REFS). Traditionally, these kinds of interactional contingencies have been studied using careful inspection and analysis (both qualitative and quantitative) of manual measurements from video and audio recordings. However, recent advances in automated annotation tools (e.g., tools for vocalization detection) have opened up the possibility to investigate interactional behavior at a much larger scale, creating a need for new, validated analytical approaches.

## Tools for contingency detection (and their shortcomings)

At present, the most widely used tool with respect to automated contingency analysis of human interaction is the LENA system (REFS). The LENA system includes both a recording device and a set of proprietary software tools that enable the researcher to collect long-format (16-hour) participant-centric audio recordings and then automatically analyze them for a range of properties, including when speakers of different types are detected (e.g., near and far female adult vocalizations). The system is meant to be used with young children wearing the device, but can also be used to capture adult language environments (REFS). The software uses the detected vocalizations to find candidate regions of vocal exchange (VABs; Vocal Activity Blocks) between the target child and nearby adults and then calculates the estimated number of speaker exchanges involving the child on the basis of temporal contingency (i.e., <5 seconds of silence between child and woman/man vocalizations or vice versa), providing this information both in summary form and as vocalization metadata in their derived output file (".its" file). Validation studies of LENA's primary turn-taking measure (CTC; Conversational Turn Count) suggest that the outcome is noisy, with reliability estimates between 0.3 and 0.6 (REFS; Bulgarelli et al., under review; Cristia et al., under review), and that CTC errors are worse for younger infants than older ones (REFS).[^2] Because the LENA system has enabled researchers to quickly and easily extract estimates from many hours of audio across many children, it has stimulated a number of new research lines investigating the predictive value of CTC for children's language development outcomes (REFS). Unfortunately, however, the software is proprietary, expensive, and can only be used with recordings made with the LENA device. It is also designed specifically to work for child wearers and so the CTC output has little utility for those interested in adult-centric audio or even vocal and multi-modal exchanges between non-human animals.

[^2]: Note that most CTC error estimates inherit error from earlier steps in the processing pipeline (e.g., misidentifying the speech as silence).

Outside of the LENA context, 

- Roberts et al (2015)
- Heldner & Edlund? Bosch
- Animal studies??

- Variation in relevant timing windows (applicable windows differ; REFS)
- Variation in what vocalizations "count"
- Variation in how many "speakers" are involved

## Two-column images

```{r 2-col-image, fig.env = "figure*", fig.pos = "h", fig.width=4, fig.height=2, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "This image spans both columns. And the caption text is limited to 0.8 of the width of the document."}
# Note: Image must be in .png file format for the readPNG function to work.
img <- png::readPNG("figs/walrus.png")
grid::grid.raster(img)
```

## One-column images

```{r image, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=2, fig.height=2, set.cap.width=T, num.cols.cap=1, fig.cap = "One column image."}
img <- png::readPNG("figs/lab_logo_stanford.png")
grid::grid.raster(img)
```


## R Plots

```{r plot, fig.env="figure", fig.pos = "H", fig.align = "center", fig.width=2, fig.height=2, fig.cap = "R plot" }
x <- 0:100
y <- 2 * (x + rnorm(length(x), sd = 3) + 3)

ggplot2::ggplot(data = data.frame(x, y), 
                aes(x = x, y = y)) + 
  geom_point() + 
  geom_smooth(method = "lm")
```


## Tables

```{r xtable, results="asis"}
n <- 100
x <- rnorm(n)
y <- 2*x + rnorm(n)
out <- lm(y ~ x)

tab1 <- xtable::xtable(summary(out)$coef, digits=c(0, 2, 2, 1, 2), 
                       caption = "This table prints across one column.")

print(tab1, type="latex", comment = F, table.placement = "H")
```

# Acknowledgements

Place acknowledgments (including funding information) in a section at
the end of the paper.

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent
